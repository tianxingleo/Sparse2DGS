# 场景重建 Pipeline - 项目说明

## 项目概述

这是一个完整的从手机拍摄视频到高质量3D场景重建的Pipeline，结合了 BrainDance 的抽帧+GLOMAP重建流程与 Sparse2DGS 的先进重建技术。

## 项目结构

```
scene2sparse2dgs/
├── scene_pipeline.py     # 主 Pipeline 脚本
├── run.sh               # 快速启动脚本
├── requirements.txt     # Python 依赖
├── README.md           # 详细文档
├── QUICKSTART.md       # 快速开始指南
└── .gitignore         # Git 忽略文件
```

## 核心特性

### 1. 智能数据处理
- **自动抽帧**：使用 FFmpeg 从视频中提取关键帧
- **质量过滤**：九宫格评分算法自动过滤模糊图片
- **均匀采样**：保证视角覆盖，避免某个视角缺失

### 2. GLOMAP 稀疏重建
- **特征提取**：COLMAP SIFT 特征提取
- **图像匹配**：COLMAP 顺序匹配算法（Overlap 25%）
- **全局重建**：**GLOMAP 全局优化重建**（比传统 COLMAP 更精确）
- **自动整理**：自动整理目录结构，适配 Sparse2DGS

**为什么使用 GLOMAP？**
- GLOMAP 是全局优化重建系统，比传统 COLMAP 更精确
- 特别适合大规模场景重建
- 鲁棒性更强，对噪声和异常值不敏感
- 更好的尺度估计和相机位姿初始化

### 3. Sparse2DGS 训练
- **CLMVSNet 深度估计**：生成密集深度先验
- **几何优先优化**：稀视角下的鲁棒重建
- **高质量输出**：比传统 2DGS 精度提高 2.5 倍

## 技术亮点

### 相比原始 Sparse2DGS 的改进

1. **场景优化**
   - 增加图像数量限制（300张，适合场景重建）
   - 优化抽帧策略（4 FPS，平衡质量和效率）
   - 调整训练参数（30000 迭代）

2. **自动化流程**
   - 一键从视频到 3D 模型
   - 无需手动数据预处理
   - 自动质量检测和过滤

3. **用户友好**
   - 清晰的进度输出
   - 彩色日志输出
   - 详细的错误提示

### 相比 BrainDance 的改进

1. **更先进的重建算法**
   - Sparse2DGS vs 3DGS：更精确的表面重建
   - MVS 深度先验：解决稀视角问题
   - 几何优化：更准确的细节

2. **专为场景优化**
   - 支持大规模场景（300张图像）
   - 室内场景优化
   - 无需 mask（纯几何重建）

## 使用流程

```
视频输入 → 抽帧 → 质量过滤 → GLOMAP重建 → Sparse2DGS训练 → 3D模型输出
```

### Step 1: 视频处理
- FFmpeg 抽帧（4 FPS）
- 缩放到 1920px
- 输出：高质量图像

### Step 2: 质量过滤
- 九宫格 Laplacian 评分
- 保留 90% 高质量图片
- 均匀采样保证覆盖

### Step 3: GLOMAP 重建
- COLMAP SIFT 特征提取
- COLMAP 顺序匹配
- **GLOMAP 全局优化重建**
- 输出：相机姿态 + 稀疏点云

**GLOMAP 优势：**
- 全局优化，避免局部最优
- 更精确的相机位姿估计
- 更好的尺度一致性
- 适合大规模场景

### Step 4: Sparse2DGS 训练
- CLMVSNet 深度估计
- Gaussian Splatting 初始化
- 几何优先优化
- 输出：高质量点云

## 性能指标

### 图像数量
- **推荐范围**：200-350 张
- **默认设置**：300 张
- **最少要求**：50 张（质量下降）

### 训练时间
- **RTX 3090**：30-60 分钟
- **RTX 2080 Ti**：1-2 小时
- **GTX 1080 Ti**：2-3 小时

### 内存需求
- **系统内存**：16GB+
- **显存**：8GB+（推荐 11GB+）
- **磁盘空间**：10GB+

## 适用场景

### ✅ 推荐场景
- 室内房间
- 办公环境
- 展览馆
- 博物馆
- 商场

### ⚠️ 慎用场景
- 室外大场景（需要更多图像）
- 包含移动物体（导致重建失败）
- 反光表面过多（玻璃、镜子）
- 动态光照（闪烁灯光）

## 拍摄建议

### 最佳实践
1. **相机运动**
   - 围绕场景 360 度拍摄
   - 保持稳定移动
   - 避免快速转向

2. **拍摄距离**
   - 保持适当距离（1-3米）
   - 远近结合
   - 避免过远或过近

3. **光照条件**
   - 自然光最佳
   - 避免过度曝光
   - 确保光照均匀

4. **视角重叠**
   - 相邻图像重叠 60-80%
   - 每个角度多拍几张
   - 覆盖所有重要区域

## 故障排查

### COLMAP 失败
```
症状：特征提取或匹配失败
原因：图像质量差或光照不佳
解决：增加图像数量，提高视频质量
```

### 训练崩溃
```
症状：CUDA out of memory
原因：显存不足
解决：减少 MAX_IMAGES，降低分辨率
```

### 重建质量差
```
症状：模型模糊或缺失细节
原因：图像不足或视角覆盖不够
解决：增加图像数量，改善拍摄技巧
```

## 下一步优化

### 短期改进
1. 添加 GPU 加速的 COLMAP
2. 支持多分辨率训练
3. 添加进度条显示
4. 支持断点续训

### 长期计划
1. 集成 NeRF 后处理
2. 添加自动纹理映射
3. 支持视频实时预览
4. Web 界面

## 致谢

本项目基于以下开源项目：
- [BrainDance](https://github.com/tianxingleo/BrainDance) - 抽帧和 COLMAP 集成
- [Sparse2DGS](https://github.com/Wuuu3511/Sparse2DGS) - 核心重建算法
- [COLMAP](https://colmap.github.io/) - 稀疏重建
- [CLMVSNet](https://github.com/KaiqiangXiong/CL-MVSNet) - 深度估计

## 许可证

本项目采用 MIT 许可证。

## 联系方式

- 作者：天马行空
- Email：tianxingleo@gmail.com
- GitHub：tianxingleo

---

**Happy Reconstruction! 🎉**
